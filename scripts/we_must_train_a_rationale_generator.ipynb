{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c492987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gpt3\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from typing import List, Dict, Any, NewType\n",
    "\n",
    "InputDataClass = NewType(\"InputDataClass\", Any)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "from transformers import (\n",
    "    T5Config,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "import transformers\n",
    "from transformers import Trainer\n",
    "\n",
    "#from feature_conversion_methods import format_instance\n",
    "\n",
    "from custom_args import (\n",
    "    DataTrainingArguments,\n",
    "    ModelArguments\n",
    ")\n",
    "from metrics import evaluate\n",
    "import torch\n",
    "import datasets\n",
    "import git\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "from tqdm import trange\n",
    "import random \n",
    "import pandas as pd \n",
    "import jsonlines\n",
    "from copy import deepcopy \n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "transformers.logging.set_verbosity_info()\n",
    "import re\n",
    "def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n",
    "    \"\"\"\n",
    "    Override logging levels of different modules based on their name as a prefix.\n",
    "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
    "\n",
    "    Args:\n",
    "        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n",
    "        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
    "          Default is `[\"\"]` to match all active loggers.\n",
    "          The match is a case-sensitive `module_name.startswith(prefix)`\n",
    "    \"\"\"\n",
    "    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n",
    "    for name in logging.root.manager.loggerDict:\n",
    "        if re.match(prefix_re, name):\n",
    "            logging.getLogger(name).setLevel(level)\n",
    "set_global_logging_level(logging.ERROR, [\"datasets\"])\n",
    "\n",
    "\n",
    "CONFIG_MAPPING = {\"t5\": T5Config}\n",
    "MODEL_MAPPING = {\"t5\": T5ForConditionalGeneration}\n",
    "TOKENIZER_MAPPING = {\"t5\": T5Tokenizer}\n",
    "\n",
    "\n",
    "def set_other_seeds(seed):\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "# inspired by DefaultDataCollator from:\n",
    "# https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py\n",
    "# modified to perform batch-level padding.\n",
    "class SequenceCollator:\n",
    "    def __init__(self, model, pad_token):\n",
    "        self.model = model\n",
    "        self.pad_token_mapping = {\n",
    "            \"labels\": -100,\n",
    "            \"attention_mask\": 0,\n",
    "            \"decoder_attention_mask\": 0,\n",
    "            \"input_ids\": pad_token,\n",
    "        }\n",
    "\n",
    "        self.columns = [\n",
    "            \"input_ids\",\n",
    "            \"attention_mask\",\n",
    "            \"labels\",\n",
    "            \"decoder_attention_mask\",\n",
    "        ]\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, InputDataClass]]) -> Dict[str, torch.Tensor]:\n",
    "        # re-format inputs for training\n",
    "        batch = {}\n",
    "        for key in examples[0].keys():\n",
    "            if key in self.columns:\n",
    "                tmp_list = []\n",
    "                for item in examples:\n",
    "                    tmp_list.append(item[key])\n",
    "\n",
    "                # pad lists to max length\n",
    "                if isinstance(tmp_list[0], list):\n",
    "                    max_length = max(map(len, tmp_list))\n",
    "                    tmp_list = [\n",
    "                        el + [self.pad_token_mapping[key]] * (max_length - len(el))\n",
    "                        for el in tmp_list\n",
    "                    ]\n",
    "\n",
    "                batch[key] = torch.tensor(tmp_list, dtype=torch.long)\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038d3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import pdb\n",
    "\"\"\"\n",
    "Example-to-Feature conversion methods\n",
    "Modified from\n",
    "https://github.com/salesforce/cos-e/blob/master/code/generation/train_commonsenseqa_v1.0.py and \"\"_v1.11.py (identical)\n",
    "as well as Tensorflow code for WTF?: \n",
    "https://github.com/google-research/google-research/blob/master/wt5/wt5/preprocessors.py\n",
    "\"\"\"\n",
    "# This code is based on https://github.com/allenai/label_rationale_association/blob/main/feature_conversion_methods.py\n",
    "\n",
    "unified_qa_esnli_label_mapping = {0: 'yes', 1: 'maybe', 2: 'no'}\n",
    "unified_qa_esnli_label_mapping_upper = {0: 'Yes', 1: 'Maybe', 2: 'No'} \n",
    "wt5_esnli_label_mapping = {0: 'entailment', 1: 'neutral', 2: 'contradiction'} \n",
    "unified_qa_sbic_label_mapping = {\"offensive\": 'Yes', \"not offensive\": 'No'}\n",
    "\n",
    "def format_instance(\n",
    "        example,\n",
    "        tokenizer,\n",
    "        explanation_sep,\n",
    "        max_seq_length=None,\n",
    "        datasource=None,\n",
    "        io_format=None, \n",
    "):\n",
    "    assert datasource in {\"cos_e\", \"esnli\", \"sbic\", \"sensemaking\", \"ecqa\"}\n",
    "    input_string, answer_string = cqa_formatting(example, io_format, explanation_sep, datasource)\n",
    "    \n",
    "#     if datasource in [\"cos_e\", \"ecqa\"]:\n",
    "#         input_string, answer_string = cqa_formatting(example, io_format, explanation_sep, datasource)\n",
    "#     elif datasource == \"esnli\":\n",
    "#         input_string, answer_string = esnli_formatting(example, io_format, explanation_sep)\n",
    "#     elif datasource == 'sbic':\n",
    "#         input_string, answer_string = sbic_formatting(example, io_format, explanation_sep)\n",
    "#     elif datasource == 'sensemaking':\n",
    "#         input_string, answer_string = sensemaking_formatting(example, io_format, explanation_sep)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unknown task. Currently supported: esnli, cos_e, sbic, sensemaking, ecqa.\")\n",
    "    \n",
    "#     if 'unified' in io_format and 'unifew' not in io_format:\n",
    "#         input_string += '</s>'\n",
    "\n",
    "    input_string = ' '.join(input_string.split())\n",
    "    answer_string = ' '.join(answer_string.split())\n",
    "\n",
    "    input_string = ' '.join(input_string.split())\n",
    "    answer_string = ' '.join(answer_string.split())\n",
    "\n",
    "    encodings = tokenizer.encode_plus(\n",
    "        input_string,\n",
    "        max_length=max_seq_length,\n",
    "        pad_to_max_length=False,\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # note even with \"lm_labels.shift_right()\", the decoder attention mask length is still correct since we remove the last token\n",
    "    dec = tokenizer.encode_plus(\n",
    "        answer_string,\n",
    "        max_length=max_seq_length,\n",
    "        pad_to_max_length=False,\n",
    "        return_token_type_ids=False,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "\n",
    "    encodings[\"labels\"] = dec[\"input_ids\"]\n",
    "    encodings[\"decoder_attention_mask\"] = dec[\"attention_mask\"]\n",
    "    encodings[\"question_encoding\"] = encodings[\"input_ids\"]\n",
    "\n",
    "    #return encodings\n",
    "    return {**example, **encodings}\n",
    "\n",
    "#这里很简单 定义好输入输出string就可以的\n",
    "def cqa_formatting(item, io_format, explanation_sep, datasource):\n",
    "    question = item[\"question\"]\n",
    "    answer = item[\"answer\"]\n",
    "    abstr_expl = item[\"abstractive_explanation\"].lower() if datasource == 'cos_e' else item[\"explanation\"].lower()\n",
    "\n",
    "\n",
    "    if io_format == 't5_fewshot_infilling_with_choices':\n",
    "        input_string = f\"explain {datasource} question: {question} choice: \" + \" choice: \".join(item[\"choices\"]) + f\" <extra_id_0> {explanation_sep} <extra_id_1>\"\n",
    "        answer_string = f\"<extra_id_0> {answer} <extra_id_1> {abstr_expl} <extra_id_2>\"\n",
    "    elif io_format == 't5_fewshot_infilling_more_natural':\n",
    "        input_string = f\"explain {datasource} question: {question} choice: \" + \" choice: \".join(item[\"choices\"]) + f\" The answer is <extra_id_0> {explanation_sep} <extra_id_1>\"\n",
    "        answer_string = f\"<extra_id_0> {answer} <extra_id_1> {abstr_expl} <extra_id_2>\"\n",
    "    elif io_format == \"squad\": \n",
    "        input_string = f\"explain {datasource} question: {question} context: \" + ', '.join(item['choices']) # explain cos_e question: When getting in shape you need to have this in between workouts? context: give up, period of recovery, jogging\n",
    "        answer_string = f\"{answer} {explanation_sep} {abstr_expl}\" # period of recovery because without a period of recovery you will not get any gains.\n",
    "    elif io_format == \"record\": \n",
    "        # might not work because cos_e doesn't have a passage \n",
    "        input_string = f\"explain {datasource} query: {question} entities: \" + ', '.join(item['choices']) # explain cos_e query: When getting in shape you need to have this in between workouts? entities: give up, period of recovery, jogging\n",
    "        answer_string = f\"{answer} {explanation_sep} {abstr_expl}\" # period of recovery because without a period of recovery you will not get any gains.\n",
    "    elif io_format == 'unifiedqa_matching':\n",
    "        choice_ids = ['(A)', '(B)', '(C)', '(D)', '(E)']\n",
    "        input_string = f'explain {question.lower()} \\\\n'\n",
    "        for choice_id, choice in zip(choice_ids, item[\"choices\"]):\n",
    "            input_string += f' {choice_id} {choice.lower()}'\n",
    "        answer_string = f\"{answer.lower()} {explanation_sep} {abstr_expl.lower()}\"\n",
    "        answer_string = answer_string.lower()\n",
    "    elif io_format == 't5_fewshot_infilling_without_choices_use_refined_expl':\n",
    "        input_string = f\"explain {datasource} question: {question} choice: \" + \" choice: \".join(item[\"choices\"]) + f\" <extra_id_0> {explanation_sep} <extra_id_1>\"\n",
    "        input_string = f\"explain {datasource} question: {question} answer: {answer}\" + f\" {explanation_sep} <extra_id_0>\"\n",
    "        answer_string = f\"<extra_id_0> {item['our_explanation']} <extra_id_1>\"\n",
    "        #print(item)\n",
    "        #print(input_string)\n",
    "        #print(answer_string)\n",
    "        #pdb.set_trace()\n",
    "    else:\n",
    "        raise ValueError(\"The IO format is not supported. Choose `standard` or `masked_cause_generate`.\")\n",
    "    \n",
    "    return input_string, answer_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7320d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6bc1797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "11/19/2022 22:54:10 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 8, distributed training: False, 16-bits training: False\n",
      "11/19/2022 22:54:10 - INFO - __main__ -   Save path: ./cos_e_output/111922_225410\n",
      "11/19/2022 22:54:10 - INFO - __main__ -   Git branch: dev\n",
      "11/19/2022 22:54:10 - INFO - __main__ -   Git hash: 1cbb5c3b4e53baf31cbafc20d9655c63f091f901\n"
     ]
    }
   ],
   "source": [
    "#关键是cos-e数据集的处理的\n",
    "og_start_time = time.time()\n",
    "\n",
    "#parser = HfArgumentParser(\n",
    "#    (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    "#)\n",
    "parser = HfArgumentParser(\n",
    "    (ModelArguments, DataTrainingArguments, TrainingArguments)\n",
    ")\n",
    "\n",
    "model_args, data_args, training_args, unused_args = parser.parse_args_into_dataclasses(\n",
    "    [\"--model_type\", \"t5-base\",\n",
    "     \"--tokenizer_name\", \"t5-base\",\n",
    "     \"--task_name\", \"cos_e\", \n",
    "     \"--output_dir\", \"./cos_e_output\", \n",
    "     \"--n_shots\", \"10\",\n",
    "     \"--do_train\", \"True\"], return_remaining_strings=True)\n",
    "\n",
    "if unused_args != []:\n",
    "    raise ValueError(f\"Received unused arguments: {unused_args}\")\n",
    "# make sure only one dataset split pick if manually specifying evaluation file\n",
    "\n",
    "if model_args.use_gpt3:\n",
    "    assert training_args.do_train\n",
    "    assert not training_args.do_eval\n",
    "    assert data_args.generations_filepath is None\n",
    "    if data_args.gpt3_max_eval_size is not None:\n",
    "        assert data_args.gpt3_max_eval_size <= data_args.fewshot_eval_size\n",
    "        assert data_args.gpt3_max_eval_size % 2 == 0\n",
    "        assert data_args.gpt3_max_eval_size % 3 == 0\n",
    "\n",
    "if data_args.generations_filepath is not None:\n",
    "    training_args.do_train = False\n",
    "    training_args.do_eval = False\n",
    "    if \"train\" in data_args.generations_filepath:\n",
    "        data_args.train_predict = True\n",
    "        data_args.test_predict = False\n",
    "        data_args.dev_predict = False\n",
    "    elif \"test\" in data_args.generations_filepath:\n",
    "        data_args.train_predict = False\n",
    "        data_args.test_predict = True\n",
    "        data_args.dev_predict = False\n",
    "    elif \"validation\" in data_args.generations_filepath:\n",
    "        data_args.train_predict = False\n",
    "        data_args.test_predict = False\n",
    "        data_args.dev_predict = True\n",
    "\n",
    "if not training_args.do_train and data_args.generations_filepath is None:\n",
    "    if not model_args.pretrained_model_file:\n",
    "        raise Exception(\n",
    "            \"if not training a model from scratch, must specify a trained model to load for evaluation\"\n",
    "        )\n",
    "\n",
    "if training_args.do_train:\n",
    "    # create a save directory and a logfile\n",
    "    training_args.output_dir = os.path.join(\n",
    "        training_args.output_dir, datetime.now().strftime(\"%m%d%y_%H%M%S\")\n",
    "    )\n",
    "    training_args.logging_dir = training_args.output_dir\n",
    "    assert not os.path.exists(training_args.output_dir)\n",
    "    os.makedirs(training_args.output_dir)\n",
    "\n",
    "    if (\n",
    "            os.path.exists(training_args.output_dir)\n",
    "            and os.listdir(training_args.output_dir)\n",
    "            and training_args.do_train\n",
    "            and not training_args.overwrite_output_dir\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    handlers = [\n",
    "        logging.FileHandler(os.path.join(training_args.output_dir, \"logger.log\")),\n",
    "        logging.StreamHandler(),\n",
    "    ]\n",
    "else:\n",
    "    # don't overwrite existing logfile or create new directory\n",
    "    training_args.output_dir = model_args.pretrained_model_file\n",
    "    handlers = [logging.StreamHandler()]\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    "    handlers=handlers,\n",
    ")\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Save path: %s\" % training_args.output_dir)\n",
    "\n",
    "# get git hash and branch where deployed\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_hash = repo.head.object.hexsha\n",
    "git_branch = repo.active_branch.name\n",
    "logger.info(\"Git branch: %s\" % git_branch)\n",
    "logger.info(\"Git hash: %s\" % git_hash)\n",
    "\n",
    "model_class = \"t5\"\n",
    "assert data_args.task_name in {\"cos_e\", \"esnli\", \"sbic\", \"sensemaking\", \"ecqa\"}\n",
    "\n",
    "if training_args.do_train:\n",
    "    # write command and args to file\n",
    "    with open(\n",
    "            os.path.join(training_args.output_dir, \"commandline_args.txt\"), \"w\"\n",
    "    ) as f:\n",
    "        f.write(\"Git branch: \" + git_branch + \"\\n\")\n",
    "        f.write(\"Git hash: \" + git_hash + \"\\n\")\n",
    "        f.write(\"Command:\\n\")\n",
    "        f.write(\"\\n\".join(sys.argv[1:]))\n",
    "\n",
    "# Set seed\n",
    "set_seed(training_args.seed)\n",
    "set_other_seeds(training_args.seed)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# Distributed training:\n",
    "# The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053f4051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args.report_to=\"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b622134",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/19/2022 22:54:10 - INFO - __main__ -   Loading pretrained tokenizer...\n",
      "loading file https://huggingface.co/t5-base/resolve/main/spiece.model from cache at /home/huangyongfeng/.cache/huggingface/transformers/684a47ca6257e4ca71f0037771464c5b323e945fbc58697d2fad8a7dd1a2f8ba.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n",
      "loading file https://huggingface.co/t5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/t5-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/t5-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading file https://huggingface.co/t5-base/resolve/main/tokenizer.json from cache at /home/huangyongfeng/.cache/huggingface/transformers/90de37880b5ff5ac7ab70ff0bd369f207e9b74133fa153c163d14c5bb0116207.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/huangyongfeng/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /home/huangyongfeng/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n",
      "Model config T5Config {\n",
      "  \"architectures\": [\n",
      "    \"T5WithLMHeadModel\"\n",
      "  ],\n",
      "  \"d_ff\": 3072,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /home/huangyongfeng/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "CONFIG_MAPPING = {\"t5\": T5Config}\n",
    "MODEL_MAPPING = {\"t5\": T5ForConditionalGeneration}\n",
    "TOKENIZER_MAPPING = {\"t5\": T5Tokenizer}\n",
    "model_class = \"t5\"\n",
    "tokenizer_name = TOKENIZER_MAPPING[model_class]\n",
    "logger.info(\"Loading pretrained tokenizer...\")\n",
    "model_args.tokenizer_name='t5-base'\n",
    "tokenizer = tokenizer_name.from_pretrained(model_args.tokenizer_name)#, cache_dir=model_args.cache_dir)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b8ad75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTrainingArguments(task_name='cos_e', early_stopping_patience=10, overwrite_cache=False, train_predict=False, test_predict=False, dev_predict=False, version_name='v1.11', generations_filepath=None, n_shots=10, fewshot_eval_size=350, io_format='t5_fewshot_infilling_without_choices_use_refined_expl', explanation_sep='explanation', data_path=None, gpt3_max_eval_size=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_splits = {'train': None, 'validation': None, 'test': None}\n",
    "original_data_splits = {'train': None, 'validation': None, 'test': None}  \n",
    "data_args.io_format=\"t5_fewshot_infilling_without_choices_use_refined_expl\"\n",
    "data_args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d0c8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013719797134399414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840ee81cd02f4a429bb8101cfd931ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'id', 'choices', 'abstractive_explanation', 'extractive_explanation', 'answer'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(data_args.task_name, data_args.version_name)\n",
    "train_ids_list=[x['id'] for x in dataset[\"train\"]]\n",
    "dataset['train'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43fdb925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013273000717163086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8bf62bcbe940ce95f5a767c447efa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6723, 3269, 12, 6020, 7815, 0, 13, 7, 3556, 4587, 3166, 2607, 1999, 332, 8571, 2, 3520, 6, 1425, 2361, 3764, 7728, 8352, 1273, 5191, 496, 11, 8143, 6929, 4552, 4652, 7764, 6736, 401, 147, 8339, 3128, 5556, 8769, 4417, 8778, 7145, 1279, 6297, 7149, 5884, 10, 5747, 6273, 8, 9504, 8057, 1307, 2183, 1699, 88, 3228, 7178, 2140, 4048, 1041, 1, 3, 5868, 111, 7889, 5370, 8886, 2137, 6980, 9117, 1891, 7827, 1484, 14, 3668, 7090, 5, 7817, 6213, 4656, 5074, 7514, 5896, 4, 9, 7991, 58, 1887, 1598, 3994, 2212, 2274, 6830, 8826, 1604, 9008, 2013, 6521, 4793, 4338, 3923, 8091, 4904, 3938, 3900, 8156, 5806, 8363, 1787, 1496, 5753, 6351, 1104, 1222]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'id': 'cabdfc174953b4bdb8bdcc89d6592c74',\n",
       "  'question': 'What is someone not legal to buy alcohol?',\n",
       "  'choices': ['underage', 'banned', 'adult', 'rules', 'black market'],\n",
       "  'answer': 'underage',\n",
       "  'abstractive_explanation': '21 is the legal age',\n",
       "  'extractive_explanation': 'not legal to buy alcohol',\n",
       "  'our_explanation': '21 is the legal age to buy alcohol in the US'},\n",
       " {'type': 'evaluation',\n",
       "  'question': 'What is someone not legal to buy alcohol?',\n",
       "  'orig_explanation': '21 is the legal age',\n",
       "  'our_explanation': '21 is the legal age to buy alcohol in the US',\n",
       "  'id': 'cabdfc174953b4bdb8bdcc89d6592c74',\n",
       "  'choices': \"['underage', 'banned', 'adult', 'rules', 'black market']\",\n",
       "  'answer': 'underage'},\n",
       " {'question': 'What is someone not legal to buy alcohol?',\n",
       "  'id': 'cabdfc174953b4bdb8bdcc89d6592c74',\n",
       "  'choices': ['underage', 'banned', 'adult', 'rules', 'black market'],\n",
       "  'abstractive_explanation': '21 is the legal age',\n",
       "  'extractive_explanation': 'not legal to buy alcohol',\n",
       "  'answer': 'underage'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rationale generation labeled data construction 115\n",
    "import pandas as pd\n",
    "scr_csqa_labeled_path=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/handwritten_cose_v1.11_examples.csv\"\n",
    "scr_csqa_label_df=pd.read_csv(scr_csqa_labeled_path)\n",
    "scr_csqa_label_data=datasets.load_dataset('csv', data_files=scr_csqa_labeled_path)\n",
    "scr_csqa_label_ids_list=[x['id'] for x in scr_csqa_label_data['train']]\n",
    "scr_csqa_indexs_list=[train_ids_list.index(id_) for id_ in scr_csqa_label_ids_list]\n",
    "scr_csqa_label_our_explanations_list=[x['our_explanation'] for x in scr_csqa_label_data['train']]\n",
    "print(scr_csqa_indexs_list)\n",
    "data_splits={}\n",
    "data_splits['train']=dataset['train'].select(scr_csqa_indexs_list)\n",
    "\n",
    "refine_train_data=[]\n",
    "for kk, (ex,da) in enumerate(zip(scr_csqa_label_our_explanations_list, data_splits['train'])):\n",
    "#     print(da)\n",
    "    data_splits['train'][kk]['our_explanation']=ex\n",
    "    #print(type(data_splits['train'][kk]),data_splits['train'][kk].keys())\n",
    "    da['our_explanation']=ex\n",
    "    refine_train_data.append(da)\n",
    "\n",
    "\n",
    "refine_train_data[0],scr_csqa_label_data['train'][0],data_splits['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273f454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_csqa_unlabeled_train_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_train.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557ec7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013177156448364258,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfbb116a1da4706981bc37790deeec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': '5b8a3081c3235d62bc77e2d15f3ad454',\n",
       " 'question': 'A town between two mountains is located in a what?',\n",
       " 'choices': ['valley', 'hospital', 'state', 'train station', 'michigan'],\n",
       " 'answer': 'valley',\n",
       " 'abstractive_explanation': 'valleys are always between two mountains',\n",
       " 'extractive_explanation': 'A town between two mountains',\n",
       " 'our_explanation': 'A town in between mountains presumably would be in a valley, in which case it is plausable that it would be surrounded by heights in every direction.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rationale unlabeled data construction 991\n",
    "import pdb\n",
    "scr_csqa_unlabeled_test_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_test.csv\"\n",
    "fse_csqa_dev_dataset = datasets.load_dataset('csv', data_files=scr_csqa_unlabeled_test_file)\n",
    "scr_csqa_unlabeled_test_df=pd.read_csv(scr_csqa_unlabeled_test_file)\n",
    "fse_csqa_dev_data_dict={}\n",
    "for kk, da in enumerate(fse_csqa_dev_dataset['train']):\n",
    "    #pdb.set_trace()\n",
    "    id_=da['Input.id']\n",
    "    if da['Answer.acceptable']:\n",
    "        answer_accept=set(da['Answer.acceptable'].split('|'))\n",
    "    else:\n",
    "        answer_accept=set()\n",
    "    explanation_list=[da['Input.explanation_1'], \n",
    "                      da['Input.explanation_2'],\n",
    "                      da['Input.explanation_3'],\n",
    "                      da['Input.explanation_4'],\n",
    "                      da['Input.explanation_5']]\n",
    "    if id_ not in fse_csqa_dev_data_dict.keys():\n",
    "        fse_csqa_dev_data_dict[id_]={\"index\":kk,\"id\":id_,\n",
    "                                     \"accept_set_list\":[answer_accept],\n",
    "                                     \"explanation_list\":explanation_list}\n",
    "        #[[kk, id_, answer_accept, explanation_list]]\n",
    "    else:\n",
    "        fse_csqa_dev_data_dict[id_][\"accept_set_list\"].append(answer_accept)\n",
    "#discriminate 3/3 id\n",
    "id_accept_expl_list=[]\n",
    "our_accept_expl_list=[]\n",
    "id_unaccept_expl_list=[]\n",
    "for k,v in fse_csqa_dev_data_dict.items():\n",
    "    accept_set_list=v['accept_set_list']\n",
    "    assert len(accept_set_list)==3\n",
    "    #pdb.set_trace()\n",
    "    common_accept_expl_sample=set.intersection(accept_set_list[0], accept_set_list[1], accept_set_list[2])\n",
    "    #print(accept_set_list,common_accept_expl_sample)\n",
    "    #pdb.set_trace()\n",
    "    if common_accept_expl_sample:\n",
    "        id_accept_expl_list.append(k)\n",
    "        our_expl=\"\"\n",
    "        for idx in list(common_accept_expl_sample):\n",
    "            idx=int(idx)-1\n",
    "            if len(v['explanation_list'][idx]) > len(our_expl):\n",
    "                our_expl = v['explanation_list'][idx]\n",
    "                our_accept_expl_list.append(our_expl)\n",
    "    else:\n",
    "        id_unaccept_expl_list.append(k)\n",
    "\n",
    "dev_ids_list=[x['id'] for x in dataset['validation']]\n",
    "dev_accept_indexs_list=[dev_ids_list.index(id_) for id_ in id_accept_expl_list]\n",
    "dev_unaccpet_indexs_list=[dev_ids_list.index(id_) for id_ in id_unaccept_expl_list]\n",
    "dev_accept_data=dataset['validation'].select(dev_accept_indexs_list)\n",
    "dev_unaccept_data=dataset['validation'].select(dev_unaccpet_indexs_list)\n",
    "\n",
    "\n",
    "\n",
    "new_dev_accept_data=[]\n",
    "new_dev_unaccept_data=[]\n",
    "for oexp, da in zip(our_accept_expl_list,dev_accept_data):\n",
    "    da[\"our_explanation\"]=oexp\n",
    "    new_dev_accept_data.append(da)\n",
    "for da in dev_unaccept_data:\n",
    "    da[\"our_explanation\"]=oexp\n",
    "    new_dev_unaccept_data.append(da)\n",
    "        \n",
    "new_dev_accept_data[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a769b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012783288955688477,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296b307d20ff44b5a8401b67370c9362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'ed53cbea1f21072fab892031b31192d1',\n",
       " 'question': 'Where can you likely buy many poems?',\n",
       " 'choices': ['book of poetry',\n",
       "  'literature book',\n",
       "  'book store',\n",
       "  'poetry book',\n",
       "  'bookshelf'],\n",
       " 'answer': 'book store',\n",
       " 'abstractive_explanation': 'book store book',\n",
       " 'extractive_explanation': 'buy many poems',\n",
       " 'our_explanation': 'A bookstore sells a variety of books, including poetry books; chains of bookstores sometimes specialize in categories such as poetry or literature.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rationale unlabeled data construction 991\n",
    "import pdb\n",
    "scr_csqa_unlabeled_train_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_train.csv\"\n",
    "fse_csqa_train_dataset = datasets.load_dataset('csv', data_files=scr_csqa_unlabeled_train_file)\n",
    "scr_csqa_unlabeled_train_df=pd.read_csv(scr_csqa_unlabeled_train_file)\n",
    "fse_csqa_train_data_dict={}\n",
    "for kk, da in enumerate(fse_csqa_train_dataset['train']):\n",
    "    #pdb.set_trace()\n",
    "    id_=da['Input.id']\n",
    "    if da['Answer.acceptable']:\n",
    "        answer_accept=set(da['Answer.acceptable'].split('|'))\n",
    "    else:\n",
    "        answer_accept=set()\n",
    "    explanation_list=[da['Input.explanation_1'], \n",
    "                      da['Input.explanation_2'],\n",
    "                      da['Input.explanation_3'],\n",
    "                      da['Input.explanation_4'],\n",
    "                      da['Input.explanation_5']]\n",
    "    if id_ not in fse_csqa_train_data_dict.keys():\n",
    "        fse_csqa_train_data_dict[id_]={\"index\":kk,\"id\":id_,\n",
    "                                     \"accept_set_list\":[answer_accept],\n",
    "                                     \"explanation_list\":explanation_list}\n",
    "        #[[kk, id_, answer_accept, explanation_list]]\n",
    "    else:\n",
    "        fse_csqa_train_data_dict[id_][\"accept_set_list\"].append(answer_accept)\n",
    "#discriminate 3/3 id\n",
    "id_accept_expl_list=[]\n",
    "our_accept_expl_list=[]\n",
    "id_unaccept_expl_list=[]\n",
    "for k,v in fse_csqa_train_data_dict.items():\n",
    "    accept_set_list=v['accept_set_list']\n",
    "    assert len(accept_set_list)==3\n",
    "    #pdb.set_trace()\n",
    "    common_accept_expl_sample=set.intersection(accept_set_list[0], accept_set_list[1], accept_set_list[2])\n",
    "    #print(accept_set_list,common_accept_expl_sample)\n",
    "    #pdb.set_trace()\n",
    "    if common_accept_expl_sample:\n",
    "        id_accept_expl_list.append(k)\n",
    "        our_expl=\"\"\n",
    "        for idx in list(common_accept_expl_sample):\n",
    "            idx=int(idx)-1\n",
    "            if len(v['explanation_list'][idx]) > len(our_expl):\n",
    "                our_expl = v['explanation_list'][idx]\n",
    "                our_accept_expl_list.append(our_expl)\n",
    "    else:\n",
    "        id_unaccept_expl_list.append(k)\n",
    "\n",
    "train_ids_list=[x['id'] for x in dataset['train']]\n",
    "train_accept_indexs_list=[train_ids_list.index(id_) for id_ in id_accept_expl_list]\n",
    "train_unaccpet_indexs_list=[train_ids_list.index(id_) for id_ in id_unaccept_expl_list]\n",
    "train_accept_data=dataset['train'].select(train_accept_indexs_list)\n",
    "train_unaccept_data=dataset['train'].select(train_unaccpet_indexs_list)\n",
    "\n",
    "\n",
    "\n",
    "new_train_accept_data=[]\n",
    "new_train_unaccept_data=[]\n",
    "for oexp, da in zip(our_accept_expl_list,train_accept_data):\n",
    "    da[\"our_explanation\"]=oexp\n",
    "    new_train_accept_data.append(da)\n",
    "for da in train_unaccept_data:\n",
    "    da[\"our_explanation\"]=oexp\n",
    "    new_train_unaccept_data.append(da)\n",
    "        \n",
    "new_train_accept_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47558b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_train_data=refine_train_data\n",
    "refine_dev_data=new_train_accept_data + new_dev_accept_data\n",
    "refine_test_data=new_train_unaccept_data + new_dev_unaccept_data\n",
    "\n",
    "refine_train_ids_list=[x['id'] for x in refine_train_data]\n",
    "refine_dev_ids_list=[x['id'] for x in refine_dev_data]\n",
    "refine_test_ids_list=[x['id'] for x in refine_test_data]\n",
    "\n",
    "#set(refine_train_ids_list).intersection(set(refine_dev_ids_list)),set(refine_train_ids_list).intersection(set(refine_test_ids_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27479596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013359546661376953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69457c11908242eeb1d2e310d5f4c77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012939453125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8804556653ae483798bb63bacfcf48c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fse_csqa_train_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_train.csv\"\n",
    "fse_csqa_dev_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_test.csv\"\n",
    "fse_csqa_train_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_train.csv\"\n",
    "fse_csqa_dev_file=\"/cognitive_comp/huangyongfeng/evaluate_LM_with_rationalization/few_shot_explanations/data/acceptability_annotations/commonsenseqa_test.csv\"\n",
    "fse_csqa_train_dataset = datasets.load_dataset('csv', data_files=fse_csqa_train_file)\n",
    "fse_csqa_dev_dataset = datasets.load_dataset('csv', data_files=fse_csqa_dev_file)\n",
    "train_ids_list=[x['id'] for x in dataset[\"train\"]]\n",
    "dev_ids_list=[x['id'] for x in dataset[\"validation\"]]\n",
    "fse_train_ids_list=[x['Input.id'] for x in fse_csqa_train_dataset['train']]\n",
    "fse_dev_ids_list=[x['Input.id'] for x in fse_csqa_dev_dataset['train']]\n",
    "fse_train_indexs_list=[train_ids_list.index(id_) for id_ in fse_train_ids_list]\n",
    "fse_dev_indexs_list=[dev_ids_list.index(id_) for id_ in fse_dev_ids_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d6040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b08a202e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'question', 'choices', 'answer', 'abstractive_explanation', 'extractive_explanation', 'our_explanation'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_data_splits={}\n",
    "our_data_splits['train']=refine_train_data\n",
    "our_data_splits['dev']=refine_dev_data\n",
    "our_data_splits['test']=refine_test_data\n",
    "refine_train_data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65fd07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2dict(refine_data):\n",
    "    refine_data_dict={}\n",
    "    for key in refine_data[0].keys():\n",
    "        refine_data_dict[key]=[x[key] for x in refine_data]\n",
    "    return refine_data_dict\n",
    "\n",
    "refine_train_data_dict = list2dict(refine_train_data)\n",
    "our_data_splits['train'] = datasets.Dataset.from_dict(refine_train_data_dict)\n",
    "\n",
    "refine_dev_data_dict = list2dict(refine_dev_data)\n",
    "our_data_splits['dev'] = datasets.Dataset.from_dict(refine_dev_data_dict)\n",
    "\n",
    "refine_test_data_dict = list2dict(refine_test_data)\n",
    "our_data_splits['test'] = datasets.Dataset.from_dict(refine_test_data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e581c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013674259185791016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 115,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6a3e71a739489f9da6c29b8156fa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012601375579833984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 986,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51778a589b245f1b15c391245760e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/986 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012792825698852539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 60,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 255,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69a1a34801e4e52bfce0dce73e36db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/255 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split in ['train','dev','test']:\n",
    "    our_data_splits[split] = our_data_splits[split].map(\n",
    "            lambda x: format_instance(\n",
    "                x,\n",
    "                tokenizer,\n",
    "                data_args.explanation_sep,\n",
    "                datasource=data_args.task_name,\n",
    "                io_format=data_args.io_format\n",
    "            ),\n",
    "            batched=False,\n",
    "            load_from_cache_file=False,\n",
    "        )\n",
    "\n",
    "# for split in dataset.keys():\n",
    "#     if dataset[split] is not None:\n",
    "#         dataset[split] = dataset[split].map(\n",
    "#             lambda x: format_instance(\n",
    "#                 x,\n",
    "#                 tokenizer,\n",
    "#                 data_args.explanation_sep,\n",
    "#                 datasource=data_args.task_name,\n",
    "#                 io_format=data_args.io_format\n",
    "#             ),\n",
    "#             batched=False,\n",
    "#             load_from_cache_file=False,\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d419d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceCollator:\n",
    "    def __init__(self, model, pad_token):\n",
    "        self.model = model\n",
    "        self.pad_token_mapping = {\n",
    "            \"labels\": -100,\n",
    "            \"attention_mask\": 0,\n",
    "            \"decoder_attention_mask\": 0,\n",
    "            \"input_ids\": pad_token,\n",
    "        }\n",
    "\n",
    "        self.columns = [\n",
    "            \"input_ids\",\n",
    "            \"attention_mask\",\n",
    "            \"labels\",\n",
    "            \"decoder_attention_mask\",\n",
    "        ]\n",
    "\n",
    "    def __call__(self, examples: List[Dict[str, InputDataClass]]) -> Dict[str, torch.Tensor]:\n",
    "        # re-format inputs for training\n",
    "        batch = {}\n",
    "        for key in examples[0].keys():\n",
    "            if key in self.columns:\n",
    "                tmp_list = []\n",
    "                for item in examples:\n",
    "                    tmp_list.append(item[key])\n",
    "\n",
    "                # pad lists to max length\n",
    "                if isinstance(tmp_list[0], list):\n",
    "                    max_length = max(map(len, tmp_list))\n",
    "                    tmp_list = [\n",
    "                        el + [self.pad_token_mapping[key]] * (max_length - len(el))\n",
    "                        for el in tmp_list\n",
    "                    ]\n",
    "\n",
    "                batch[key] = torch.tensor(tmp_list, dtype=torch.long)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3031e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "WandbCallback requires wandb to be installed. Run `pip install wandb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2348233/2810467517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mour_data_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         data_collator=SequenceCollator(\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         ),\n\u001b[1;32m     26\u001b[0m     )\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_callbacks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdefault_callbacks\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         self.callback_handler = CallbackHandler(\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         )\n\u001b[1;32m    389\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPrinterCallback\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_tqdm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDEFAULT_PROGRESS_CALLBACK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, callbacks, model, tokenizer, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/trainer_callback.py\u001b[0m in \u001b[0;36madd_callback\u001b[0;34m(self, callback)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m         \u001b[0mcb_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3.7pytorch1.8new/lib/python3.7/site-packages/transformers/integrations.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mhas_wandb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_wandb_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mhas_wandb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"WandbCallback requires wandb to be installed. Run `pip install wandb`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_wandb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: WandbCallback requires wandb to be installed. Run `pip install wandb`."
     ]
    }
   ],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "if data_args.generations_filepath is None:\n",
    "    #callbacks = [TensorBoardCallback()]\n",
    "    if data_args.early_stopping_patience > 0:\n",
    "        callbacks.append(EarlyStoppingCallback(early_stopping_patience=data_args.early_stopping_patience))\n",
    "        training_args.load_best_model_at_end = True\n",
    "    else:\n",
    "        training_args.load_best_model_at_end = False  # use the last model state\n",
    "    training_args.metric_for_best_model = 'eval_loss'\n",
    "    training_args.greater_is_better = False\n",
    "    if training_args.eval_steps is None:\n",
    "        training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
    "    else:\n",
    "        training_args.evaluation_strategy = EvaluationStrategy.STEPS\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=our_data_splits['train'],\n",
    "        eval_dataset=our_data_splits['dev'],\n",
    "        data_collator=SequenceCollator(\n",
    "            model=model_class, pad_token=tokenizer.pad_token_id\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Training. Don't train if it is use_gpt3\n",
    "if training_args.do_train and not model_args.use_gpt3:\n",
    "    start_time = time.time()\n",
    "    trainer.train()\n",
    "    train_time = time.time() - start_time\n",
    "    model = trainer.model\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    train_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args.generations_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabbfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20df38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87401663",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad378fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
